{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading movie-corpus to /Users/dungminhdang/.convokit/downloads/movie-corpus\n",
      "Downloading movie-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip (40.9MB)... Done\n"
     ]
    }
   ],
   "source": [
    "from convokit import Corpus, download\n",
    "\n",
    "corpus = Corpus(filename=download(\"movie-corpus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 9035\n",
      "Number of Utterances: 304713\n",
      "Number of Conversations: 83097\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utterance(id: 'L438276', conversation_id: L438272, reply-to: L438275, speaker: Speaker(id: 'u7001', vectors: [], meta: ConvoKitMeta({'character_name': 'DOOLITTLE', 'movie_idx': 'm468', 'movie_name': 'pearl harbor', 'gender': '?', 'credit_pos': '?'})), timestamp: None, text: 'No baseball diamonds, Red.', vectors: [], meta: ConvoKitMeta({'movie_id': 'm468', 'parsed': [{'rt': 2, 'toks': [{'tok': 'No', 'tag': 'DT', 'dep': 'det', 'up': 1, 'dn': []}, {'tok': 'baseball', 'tag': 'NN', 'dep': 'nsubj', 'up': 2, 'dn': [0]}, {'tok': 'diamonds', 'tag': 'NNS', 'dep': 'ROOT', 'dn': [1, 3, 4, 5]}, {'tok': ',', 'tag': ',', 'dep': 'punct', 'up': 2, 'dn': []}, {'tok': 'Red', 'tag': 'NNP', 'dep': 'npadvmod', 'up': 2, 'dn': []}, {'tok': '.', 'tag': '.', 'dep': 'punct', 'up': 2, 'dn': []}]}]}))\n"
     ]
    }
   ],
   "source": [
    "utt = corpus.random_utterance()\n",
    "print(utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: L438276 \n",
      "\n",
      "Reply_to: L438275 \n",
      "\n",
      "Timestamp: None \n",
      "\n",
      "Text: No baseball diamonds, Red. \n",
      "\n",
      "Conversation ID: L438272 \n",
      "\n",
      "Speaker ID: u7001\n"
     ]
    }
   ],
   "source": [
    "# primary data fields\n",
    "print(\"ID:\", utt.id, \"\\n\")\n",
    "print(\"Reply_to:\", utt.reply_to, \"\\n\")\n",
    "print(\"Timestamp:\", utt.timestamp, \"\\n\")\n",
    "print(\"Text:\", utt.text, \"\\n\")\n",
    "print(\"Conversation ID:\", utt.conversation_id, \"\\n\")\n",
    "print(\"Speaker ID:\", utt.speaker.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation('id': 'L82415', 'utterances': ['L82416', 'L82415'], 'meta': ConvoKitMeta({'movie_idx': 'm267', 'movie_name': 'being john malkovich', 'release_year': '1999', 'rating': '7.90', 'votes': '115008', 'genre': \"['comedy', 'drama', 'fantasy', 'romance']\"}))\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvoKitMeta({'movie_idx': 'm267', 'movie_name': 'being john malkovich', 'release_year': '1999', 'rating': '7.90', 'votes': '115008', 'genre': \"['comedy', 'drama', 'fantasy', 'romance']\"})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo = corpus.random_conversation()\n",
    "print(convo)\n",
    "print()\n",
    "convo.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83097"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation({'obj_type': 'conversation', 'vectors': [], 'tree': None, 'owner': <convokit.model.corpus.Corpus object at 0x31c088880>, 'id': 'L82415', 'meta': ConvoKitMeta({'movie_idx': 'm267', 'movie_name': 'being john malkovich', 'release_year': '1999', 'rating': '7.90', 'votes': '115008', 'genre': \"['comedy', 'drama', 'fantasy', 'romance']\"})})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.conversations['L82415']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utterance(id: 'L1045', conversation_id: L1044, reply-to: L1044, speaker: Speaker(id: 'u0', vectors: [], meta: ConvoKitMeta({'character_name': 'BIANCA', 'movie_idx': 'm0', 'movie_name': '10 things i hate about you', 'gender': 'f', 'credit_pos': '4'})), timestamp: None, text: 'They do not!', vectors: [], meta: ConvoKitMeta({'movie_id': 'm0', 'parsed': [{'rt': 1, 'toks': [{'tok': 'They', 'tag': 'PRP', 'dep': 'nsubj', 'up': 1, 'dn': []}, {'tok': 'do', 'tag': 'VBP', 'dep': 'ROOT', 'dn': [0, 2, 3]}, {'tok': 'not', 'tag': 'RB', 'dep': 'neg', 'up': 1, 'dn': []}, {'tok': '!', 'tag': '.', 'dep': 'punct', 'up': 1, 'dn': []}]}]}))\n"
     ]
    }
   ],
   "source": [
    "print(next(corpus.iter_utterances()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_texts = {}\n",
    "\n",
    "for conv_id in corpus.get_conversation_ids():\n",
    "    utt_list = []\n",
    "    for utt_id in corpus.get_conversation(conv_id).get_utterance_ids():\n",
    "        utt = corpus.get_utterance(utt_id)\n",
    "        utt_list.append((utt.text.strip(), utt_id))\n",
    "    conversation_texts[conv_id] = [x[0] for x in sorted(utt_list, key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83097"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conversation_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1044 ['They do to!', 'They do not!']\n",
      "L984 ['She okay?', 'I hope so.']\n",
      "L924 ['Wow', \"Let's go.\"]\n",
      "L870 ['I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?', 'No', \"Okay -- you're gonna need to learn how to lie.\"]\n",
      "L866 [\"I figured you'd get to the good stuff eventually.\", 'What good stuff?', 'The \"real you\".', 'Like my fear of wearing pastels?']\n"
     ]
    }
   ],
   "source": [
    "for key in list(conversation_texts.keys())[:5]:\n",
    "    print(key, conversation_texts[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They do to!\n",
      "\n",
      "    They do not!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus.get_conversation('L1044').print_conversation_structure(lambda utt: utt.text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She okay?\n",
      "\n",
      "    I hope so.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus.get_conversation('L984').print_conversation_structure(lambda utt: utt.text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow\n",
      "\n",
      "    Let's go.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus.get_conversation('L924').print_conversation_structure(lambda utt: utt.text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
      "\n",
      "    No\n",
      "\n",
      "        Okay -- you're gonna need to learn how to lie.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus.get_conversation('L870').print_conversation_structure(lambda utt: utt.text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I figured you'd get to the good stuff eventually.\n",
      "\n",
      "    What good stuff?\n",
      "\n",
      "        The \"real you\".\n",
      "\n",
      "            Like my fear of wearing pastels?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus.get_conversation('L866').print_conversation_structure(lambda utt: utt.text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221616\n",
      "[('They do to!', 'They do not!'), ('She okay?', 'I hope so.'), ('Wow', \"Let's go.\"), ('I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?', 'No'), ('No', \"Okay -- you're gonna need to learn how to lie.\"), (\"I figured you'd get to the good stuff eventually.\", 'What good stuff?'), ('What good stuff?', 'The \"real you\".'), ('The \"real you\".', 'Like my fear of wearing pastels?'), ('do you listen to this crap?', 'What crap?'), ('What crap?', \"Me.  This endless ...blonde babble. I'm like, boring myself.\")]\n"
     ]
    }
   ],
   "source": [
    "def extract_conv_pairs(conversation_texts):\n",
    "    all_pairs = []\n",
    "    for conv_id in conversation_texts:\n",
    "        for i in range(len(conversation_texts[conv_id]) - 1):\n",
    "            all_pairs.append((conversation_texts[conv_id][i], conversation_texts[conv_id][i+1]))\n",
    "    return all_pairs\n",
    "\n",
    "all_conv_pairs = extract_conv_pairs(conversation_texts)\n",
    "\n",
    "print(len(all_conv_pairs))\n",
    "print(all_conv_pairs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_root = f\"{pathlib.Path.home()}/Projects/AI-ML/datasets/nlp_data\"\n",
    "\n",
    "datafile = os.path.join(data_root, \"formatted_movie_lines.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing newly formatted file...\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "delimiter = '\\t'\n",
    "# Unescape the delimiter\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "# Write new csv file\n",
    "print(\"\\nWriting newly formatted file...\")\n",
    "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
    "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
    "    for pair in all_conv_pairs:\n",
    "        writer.writerow(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample lines from file:\n",
      "b'They do to!\\tThey do not!\\n'\n",
      "b'She okay?\\tI hope so.\\n'\n",
      "b\"Wow\\tLet's go.\\n\"\n",
      "b'\"I\\'m kidding.  You know how sometimes you just become this \"\"persona\"\"?  And you don\\'t know how to quit?\"\\tNo\\n'\n",
      "b\"No\\tOkay -- you're gonna need to learn how to lie.\\n\"\n",
      "b\"I figured you'd get to the good stuff eventually.\\tWhat good stuff?\\n\"\n",
      "b'What good stuff?\\t\"The \"\"real you\"\".\"\\n'\n",
      "b'\"The \"\"real you\"\".\"\\tLike my fear of wearing pastels?\\n'\n",
      "b'do you listen to this crap?\\tWhat crap?\\n'\n",
      "b\"What crap?\\tMe.  This endless ...blonde babble. I'm like, boring myself.\\n\"\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample lines from file:\")\n",
    "printLines(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, name) -> None:\n",
    "        \n",
    "        self.name = name\n",
    "        self.trimed = 0\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.word2index = {}\n",
    "        self.index2word = {EOS_token: \"<EOS>\", SOS_token: \"<SOS>\", PAD_token: \"<PAD>\"}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 3\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word in self.word2count:\n",
    "            self.word2count[word] += 1\n",
    "        else:\n",
    "            self.word2count[word] = 1\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def trim(self, min_count):\n",
    "        if self.trimed >= min_count:\n",
    "            return\n",
    "        self.trimed = min_count\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= self.trimed:\n",
    "                keep_words.append((k, v))\n",
    "\n",
    "        print(\"keep_words {} / {} = {:.4f}\".format(\n",
    "            len(keep_words), len(self.word2count), float(len(keep_words)) / len(self.word2count)\n",
    "        ))\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "        for word, count in keep_words:\n",
    "            self.addWord(word)\n",
    "            self.word2count[word] = count\n",
    "\n",
    "    def encode(self, sentence):\n",
    "        return [self.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        words = []\n",
    "        for idx in ids:\n",
    "            if idx == EOS_token:\n",
    "                break\n",
    "            else:\n",
    "                words.append(self.index2word[idx])\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Vocabulary(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# Returns True if both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using the ``filterPair`` condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus_name, datafile):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.n_words)\n",
    "    return voc, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 221616 sentence pairs\n",
      "Trimmed to 64585 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 18093\n",
      "\n",
      "pairs:\n",
      "['they do to !', 'they do not !']\n",
      "['she okay ?', 'i hope so .']\n",
      "['wow', 'let s go .']\n",
      "['what good stuff ?', 'the real you .']\n",
      "['the real you .', 'like my fear of wearing pastels ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['have fun tonight ?', 'tons']\n"
     ]
    }
   ],
   "source": [
    "voc, pairs = loadPrepareData(\"movie-corpus\", datafile)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 7837 / 18090 = 0.4332\n",
      "Trimmed from 64585 pairs to 53386, 0.8266 of total\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch data\n",
    "\n",
    "[padded_batch_of_sequences](https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch)\n",
    "\n",
    "![Padded batch](images/batch-padded.png)\n",
    "\n",
    "> So, the data preparation work should be complete by now, right? Not really.. Because there is still one pressing problem, mainly in terms of how much compute do we have to do when compared to the actually required computations.\n",
    "> \n",
    "> For the sake of understanding, let's also assume that we will matrix multiply the above padded_batch_of_sequences of shape (6, 9) with a weight matrix W of shape (9, 3).\n",
    ">\n",
    "> Thus, we will have to perform 6x9 = 54 multiplication and 6x8 = 48 addition                     (nrows x (n-1)_cols) operations, only to throw away most of the computed results since they would be 0s (where we have pads). The actual required compute in this case is as follows:\n",
    "```text\n",
    " 9-mult  8-add \n",
    " 8-mult  7-add \n",
    " 6-mult  5-add \n",
    " 4-mult  3-add \n",
    " 3-mult  2-add \n",
    " 2-mult  1-add\n",
    "---------------\n",
    "32-mult  26-add\n",
    "   \n",
    "------------------------------  \n",
    "#savings: 22-mult & 22-add ops  \n",
    "          (32-54)  (26-48) \n",
    "```\n",
    "> That's a LOT more savings even for this very simple (toy) example. You can now imagine how much compute (eventually: cost, energy, time, carbon emission etc.) can be saved using pack_padded_sequence() for large tensors with millions of entries, and million+ systems all over the world doing that, again and again.\n",
    ">\n",
    "> The functionality of pack_padded_sequence() can be understood from the figure below, with the help of the used color-coding:\n",
    "\n",
    "![Packed sentences](images/batch-packed-sentences.png)\n",
    "> As a result of using pack_padded_sequence(), we will get a tuple of tensors containing (i) the flattened (along axis-1, in the above figure) sequences , (ii) the corresponding batch sizes, tensor([6,6,5,4,3,3,2,2,1]) for the above example.\n",
    "> \n",
    "> The data tensor (i.e. the flattened sequences) could then be passed to objective functions such as CrossEntropy for loss calculations.\n",
    "\n",
    "## batch transposed\n",
    "\n",
    "![Batch](images/batch-transpose.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroPadding(sentence_list, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*sentence_list, fillvalue=fillvalue))\n",
    "\n",
    "def maskMatrix(tokens, value=PAD_token):\n",
    "    return (tokens != value)\n",
    "\n",
    "def prepareInputBatch(sentence_batch, voc):\n",
    "    token_list = [voc.encode(sentence) for sentence in sentence_batch]\n",
    "    lengths = torch.tensor([len(seq) for seq in token_list])\n",
    "    paddedList = zeroPadding(token_list)\n",
    "    paddedTensors = torch.LongTensor(paddedList)\n",
    "    return paddedTensors, lengths\n",
    "\n",
    "def prepareOutputBatch(sentence_batch, voc):\n",
    "    tensors, lengths = prepareInputBatch(sentence_batch, voc)\n",
    "    mask = maskMatrix(tensors)\n",
    "    maxLength = lengths.max().item()\n",
    "    return tensors, mask, maxLength\n",
    "\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key = lambda pair: len(pair[0].split(' ')), reverse=True)\n",
    "    input_batch = [p[0] for p in pair_batch]\n",
    "    output_batch = [p[1] for p in pair_batch]\n",
    "    inputTensors, inputLengths = prepareInputBatch(input_batch, voc)\n",
    "    outputTensors, outputMask, outputMaxLen = prepareOutputBatch(output_batch, voc)\n",
    "    return inputTensors, inputLengths, outputTensors, outputMask, outputMaxLen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[  19,   11,  396,   50,   11],\n",
      "        [   4,  136,   11,  387,  113],\n",
      "        [  11,    5, 2462,   14,  544],\n",
      "        [  44,  194,   99,   14,   24],\n",
      "        [   5, 2442,   10,   14,   14],\n",
      "        [   4,   14,    2,    2,    2],\n",
      "        [  10,    2,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "lengths: tensor([8, 7, 6, 6, 6])\n",
      "target_variable: tensor([[  93,  194,  128,  576,  175],\n",
      "        [ 736, 2442,   28, 6640,   13],\n",
      "        [  62,   10,  820,   50,   10],\n",
      "        [ 757,   24,    2,   64,    2],\n",
      "        [  14,  265,    0, 3238,    0],\n",
      "        [  62,  682,    0,   14,    0],\n",
      "        [ 201,   14,    0,    2,    0],\n",
      "        [ 278, 6539,    0,    0,    0],\n",
      "        [  14,   10,    0,    0,    0],\n",
      "        [   2,    2,    0,    0,    0]])\n",
      "mask: tensor([[ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True, False,  True, False],\n",
      "        [ True,  True, False,  True, False],\n",
      "        [ True,  True, False,  True, False],\n",
      "        [ True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False]])\n",
      "max_target_len: 10\n"
     ]
    }
   ],
   "source": [
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "![Bidirectional RNN](images/bidirectional-gru-encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderGru(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding, hidden_size, n_layers, dropout_p=0.1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=n_layers, dropout=dropout_p, bidirectional=True)\n",
    "\n",
    "    def forward(self, ids, lengths, hidden=None):\n",
    "        # ids: (T, B)\n",
    "        embedded = self.embedding(ids)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden) # (T, B, 2 x H)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # sum up 2 directional outputs -> (T, B, H)\n",
    "        outputs = outputs[:, :, : self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5, 20]) torch.Size([4, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 20\n",
    "embedding = nn.Embedding(voc.n_words, hidden_size)\n",
    "encoder = EncoderGru(embedding, hidden_size, n_layers=2)\n",
    "\n",
    "outputs, hidden = encoder(input_variable, lengths)\n",
    "print(outputs.shape, hidden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 7840]) torch.Size([1, 5, 20]) tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "class DecoderGru(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding, hidden_size, output_size, enc_layers, n_layers, dropout_p=0.1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout_p)\n",
    "        self.hidden_conv = nn.Linear(2 * enc_layers, n_layers)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=n_layers, dropout=dropout_p)\n",
    "        self.out_fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward_step(self, step_idx, hidden):\n",
    "        # step_idx: (1, B)\n",
    "        embedded = self.embedding(step_idx) # (1, B, H)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.out_fc(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def forward(self, encoder_outputs, encoder_hidden, max_target_len, targets):\n",
    "        batch_size = encoder_hidden.size(1) # (2 * enc_layers, B, H)\n",
    "        decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]]) # (1, B)\n",
    "        # decoder_hidden = encoder_hidden[:self.n_layers] # (2 * enc_layers, B, H) -> (n_layers, B, H)\n",
    "        decoder_hidden = self.hidden_conv(encoder_hidden.permute(2, 1, 0)).permute(2, 1, 0)\n",
    "        outputs = []\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            outputs.append(decoder_output)\n",
    "            if targets is not None:\n",
    "                decoder_input = targets[t].view(1, -1)\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1, dim=-1)\n",
    "                decoder_input = torch.LongTensor([[topi[0][i][0] for i in range(batch_size)]])\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        outputs = F.softmax(outputs, dim=-1)\n",
    "        return outputs, decoder_hidden\n",
    "        \n",
    "\n",
    "decoder = DecoderGru(embedding, hidden_size, enc_layers=2, n_layers=1, output_size=voc.n_words)\n",
    "decoder_outputs, decoder_hidden = decoder(outputs, hidden, max_target_len, target_variable)\n",
    "print(decoder_outputs.shape, decoder_hidden.shape, decoder_outputs.sum(dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 7840]) torch.Size([1, 5, 20]) tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs, decoder_hidden = decoder(outputs, hidden, max_target_len, targets=None)\n",
    "print(decoder_outputs.shape, decoder_hidden.shape, decoder_outputs.sum(dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(pred, target, mask):\n",
    "    # print(pred.shape, target.shape, mask.shape)\n",
    "    n_enabled = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(pred.view(-1, pred.size(-1)), 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask.view(-1, 1)).mean()\n",
    "    return loss, n_enabled.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 7840]) torch.Size([10, 5]) torch.Size([10, 5]) torch.Size([50, 7840])\n"
     ]
    }
   ],
   "source": [
    "print(decoder_outputs.shape, target_variable.shape, mask.shape, decoder_outputs.view(-1, decoder_outputs.size(2)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(decoder_outputs.view(-1, decoder_outputs.size(2)), 1, target_variable.view(-1, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.0310, grad_fn=<MeanBackward0>), 5)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskNLLLoss(decoder_outputs[0], target_variable[0], mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(8.8797, grad_fn=<MeanBackward0>), 35)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskNLLLoss(decoder_outputs, target_variable, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(batch_data, encoder, decoder, embedding,\n",
    "                encoder_optim, decoder_optim, embedding_optim,\n",
    "                grad_clip, teacher_forcing_ratio):\n",
    "    input_tensors, input_lengths, target_tensors, mask, max_target_len = batch_data\n",
    "    \n",
    "    embedding_optim.zero_grad()\n",
    "    encoder_optim.zero_grad()\n",
    "    decoder_optim.zero_grad()\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensors, input_lengths)\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        decoder_outputs, _ = decoder(encoder_outputs, encoder_hidden, max_target_len, target_tensors)\n",
    "    else:\n",
    "        decoder_outputs, _ = decoder(encoder_outputs, encoder_hidden, max_target_len, targets=None)\n",
    "\n",
    "    mask_loss, nTotal = maskNLLLoss(decoder_outputs, target_tensors, mask)\n",
    "    mask_loss.backward()\n",
    "\n",
    "    _ = nn.utils.clip_grad_norm_(embedding.parameters(), grad_clip)\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), grad_clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), grad_clip)\n",
    "\n",
    "    embedding_optim.step()\n",
    "    encoder_optim.step()\n",
    "    decoder_optim.step()\n",
    "\n",
    "    return mask_loss.item(), nTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dungminhdang/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100; Percent complete: 2.5%; Average loss: 4.8055\n",
      "Iteration: 200; Percent complete: 5.0%; Average loss: 3.0201\n",
      "Iteration: 300; Percent complete: 7.5%; Average loss: 2.7914\n",
      "Iteration: 400; Percent complete: 10.0%; Average loss: 2.6742\n",
      "Iteration: 500; Percent complete: 12.5%; Average loss: 2.6698\n",
      "Iteration: 600; Percent complete: 15.0%; Average loss: 2.6283\n",
      "Iteration: 700; Percent complete: 17.5%; Average loss: 2.5890\n",
      "Iteration: 800; Percent complete: 20.0%; Average loss: 2.5420\n",
      "Iteration: 900; Percent complete: 22.5%; Average loss: 2.4950\n",
      "Iteration: 1000; Percent complete: 25.0%; Average loss: 2.4758\n",
      "Iteration: 1100; Percent complete: 27.5%; Average loss: 2.4205\n",
      "Iteration: 1200; Percent complete: 30.0%; Average loss: 2.4108\n",
      "Iteration: 1300; Percent complete: 32.5%; Average loss: 2.3934\n",
      "Iteration: 1400; Percent complete: 35.0%; Average loss: 2.3443\n",
      "Iteration: 1500; Percent complete: 37.5%; Average loss: 2.3195\n",
      "Iteration: 1600; Percent complete: 40.0%; Average loss: 2.3634\n",
      "Iteration: 1700; Percent complete: 42.5%; Average loss: 2.3399\n",
      "Iteration: 1800; Percent complete: 45.0%; Average loss: 2.3284\n",
      "Iteration: 1900; Percent complete: 47.5%; Average loss: 2.3151\n",
      "Iteration: 2000; Percent complete: 50.0%; Average loss: 2.2824\n",
      "Iteration: 2100; Percent complete: 52.5%; Average loss: 2.2768\n",
      "Iteration: 2200; Percent complete: 55.0%; Average loss: 2.2906\n",
      "Iteration: 2300; Percent complete: 57.5%; Average loss: 2.2569\n",
      "Iteration: 2400; Percent complete: 60.0%; Average loss: 2.2763\n",
      "Iteration: 2500; Percent complete: 62.5%; Average loss: 2.2308\n",
      "Iteration: 2600; Percent complete: 65.0%; Average loss: 2.2637\n",
      "Iteration: 2700; Percent complete: 67.5%; Average loss: 2.2412\n",
      "Iteration: 2800; Percent complete: 70.0%; Average loss: 2.2282\n",
      "Iteration: 2900; Percent complete: 72.5%; Average loss: 2.1905\n",
      "Iteration: 3000; Percent complete: 75.0%; Average loss: 2.2404\n",
      "Iteration: 3100; Percent complete: 77.5%; Average loss: 2.1976\n",
      "Iteration: 3200; Percent complete: 80.0%; Average loss: 2.2241\n",
      "Iteration: 3300; Percent complete: 82.5%; Average loss: 2.2282\n",
      "Iteration: 3400; Percent complete: 85.0%; Average loss: 2.1925\n",
      "Iteration: 3500; Percent complete: 87.5%; Average loss: 2.1794\n",
      "Iteration: 3600; Percent complete: 90.0%; Average loss: 2.1645\n",
      "Iteration: 3700; Percent complete: 92.5%; Average loss: 2.2011\n",
      "Iteration: 3800; Percent complete: 95.0%; Average loss: 2.1882\n",
      "Iteration: 3900; Percent complete: 97.5%; Average loss: 2.1728\n",
      "Iteration: 4000; Percent complete: 100.0%; Average loss: 2.2116\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "encoder_n_layers = 1\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 32\n",
    "\n",
    "embedding = nn.Embedding(voc.n_words, hidden_size)\n",
    "encoder = EncoderGru(embedding, hidden_size, encoder_n_layers, dropout)\n",
    "decoder = DecoderGru(embedding, hidden_size, enc_layers=encoder_n_layers,\n",
    "                     n_layers=decoder_n_layers, output_size=voc.n_words, dropout_p=dropout)\n",
    "\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 4000\n",
    "print_every = 100\n",
    "\n",
    "embedding.train()\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "embedding_optimizer = torch.optim.Adam(embedding.parameters(), lr=learning_rate)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "\n",
    "print_loss = 0\n",
    "\n",
    "for iteration in range(1, n_iteration + 1):\n",
    "    batch_data = batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "    \n",
    "    loss, n_mask = train_batch(batch_data, encoder, decoder, embedding,\n",
    "                encoder_optimizer, decoder_optimizer, embedding_optimizer,\n",
    "                clip, teacher_forcing_ratio)\n",
    "    \n",
    "    print_loss += loss\n",
    "\n",
    "    if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'm', 'sorry', '.', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EvaluateMode(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_tensors, input_lengths, max_length):\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensors, input_lengths)\n",
    "        decoder_outputs, _ = decoder(encoder_outputs, encoder_hidden, max_length, targets=None)\n",
    "        decoder_scores, decoder_tokens = torch.max(decoder_outputs, dim=-1)\n",
    "\n",
    "        return decoder_tokens, decoder_scores\n",
    "    \n",
    "    def evaluate(self, voc, sentence, max_length=MAX_LENGTH):\n",
    "        indexes_batch = [voc.encode(sentence)]\n",
    "        lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "        input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "\n",
    "        tokens, scores = self(input_batch, lengths, max_length)\n",
    "        decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "        return decoded_words\n",
    "    \n",
    "evalModel = EvaluateMode(encoder, decoder)\n",
    "evalModel.eval()\n",
    "\n",
    "\n",
    "evalModel.evaluate(voc, \"to do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> . . . that s perfectly all right .\n",
      "= uh why why are you doing this ?\n",
      ">> what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "> naw ! that s science fiction stuff !\n",
      "= not where we operate .\n",
      ">> what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "> yes .\n",
      "= welcome to hard times daddy .\n",
      ">> i m sorry . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "> crime ?\n",
      "= murder sir .\n",
      ">> yes . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "> you aren t staying ?\n",
      "= this . . . seemed best .\n",
      ">> i m not sure . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "> your treat .\n",
      "= yes . my treat .\n",
      ">> what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "> yeah\n",
      "= so why are you dating jonathan ?\n",
      ">> i m sorry . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "> do what ?\n",
      "= turn her over to a stalker .\n",
      ">> i m not going to see you . <EOS> <PAD>\n",
      "> gaiijin .\n",
      "= i ll check it out .\n",
      ">> you re not . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "> what ?\n",
      "= how much time do we have ?\n",
      ">> you re a little . <EOS> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_batch = [random.choice(pairs) for _ in range(10)]\n",
    "\n",
    "for pair in eval_batch:\n",
    "    generated = ' '.join(evalModel.evaluate(voc, pair[0]))\n",
    "    print(f\"> {pair[0]}\")\n",
    "    print(f\"= {pair[1]}\")\n",
    "    print(f\">> {generated}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Decoder\n",
    "\n",
    "# Luong's attention\n",
    "\n",
    "![Global attention](images/luong-attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encoder hidden: (2 * enc_layers, B, H)\n",
    "\n",
    "class LuongAttn(nn.Module):\n",
    "\n",
    "    def __init__(self, method: str, hidden_size: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not supported\")\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if method == 'general':\n",
    "            self.attn = nn.Linear(hidden_size, hidden_size)\n",
    "        elif method == 'concat':\n",
    "            self.attn = nn.Linear(2 * hidden_size, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def general_scores(self, decoder_output, encoder_outputs):\n",
    "        # encoder_outputs: # (T, B, H)\n",
    "        # decoder_output: (1, B, H)\n",
    "        energy = self.attn(encoder_outputs) # (T, B, H)\n",
    "        return torch.sum(decoder_output * energy, dim=2)\n",
    "    \n",
    "    def dot_scores(self, decoder_output, encoder_outputs):\n",
    "        return torch.sum(decoder_output * encoder_outputs, dim=2)\n",
    "    \n",
    "    def concat_scores(self, decoder_output, encoder_outputs):\n",
    "        energy = F.tanh(self.attn(torch.cat((decoder_output.expand(encoder_outputs.size(0), -1, -1), encoder_outputs), dim=2)))\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, decoder_output, encoder_outputs):\n",
    "        # encoder output: (T, B, H)\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_scores(decoder_output, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_scores(decoder_output, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_scores(decoder_output, encoder_outputs)\n",
    "\n",
    "        attn_energies = attn_energies.t() # attn_energies: (T, B) -> (B, T)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1) # (B, 1, T)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderGru(nn.Module):\n",
    "\n",
    "    def __init__(self, attn_mode, embedding, hidden_size, output_size, enc_layers, n_layers, dropout_p=0.1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout_p)\n",
    "        self.hidden_conv = nn.Linear(2 * enc_layers, n_layers)\n",
    "        torch.nn.init.ones_(self.hidden_conv.weight)\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=n_layers, dropout=dropout_p)\n",
    "        self.attention = LuongAttn(attn_mode, hidden_size)\n",
    "        self.proj = nn.Linear(2 * hidden_size, hidden_size)\n",
    "        self.out_fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward_step(self, step_idx, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(step_idx)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        attn_weights = self.attention(output, encoder_outputs)\n",
    "        # (B, 1, T) @ (T, B, H) -> (B, 1, H)\n",
    "        attn_values = torch.bmm(attn_weights, encoder_outputs.transpose(0, 1))\n",
    "\n",
    "        attn_values = attn_values.squeeze(1) # (B, H)\n",
    "        output = output.squeeze(0) # (B, H)\n",
    "        output = torch.cat((output, attn_values), dim=1)\n",
    "        output = F.tanh(self.proj(output)) # (B, 2 * H) -> (B, H)\n",
    "        output = self.out_fc(output)\n",
    "\n",
    "        return output.unsqueeze(0), hidden\n",
    "    \n",
    "    def forward(self, encoder_outputs, encoder_hidden, max_target_len, targets):\n",
    "        batch_size = encoder_hidden.size(1) # (2 * enc_layers, B, H)\n",
    "        decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]]) # (1, B)\n",
    "        # decoder_hidden = encoder_hidden[:self.n_layers] # (2 * enc_layers, B, H) -> (n_layers, B, H)\n",
    "        decoder_hidden = self.hidden_conv(encoder_hidden.permute(2, 1, 0)).permute(2, 1, 0)\n",
    "        outputs = []\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            outputs.append(decoder_output)\n",
    "            if targets is not None:\n",
    "                decoder_input = targets[t].view(1, -1)\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1, dim=-1)\n",
    "                decoder_input = torch.LongTensor([[topi[0][i][0] for i in range(batch_size)]])\n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        outputs = F.softmax(outputs, dim=-1)\n",
    "        return outputs, decoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5, 20]) torch.Size([4, 5, 20])\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 20\n",
    "embedding = nn.Embedding(voc.n_words, hidden_size)\n",
    "encoder = EncoderGru(embedding, hidden_size, n_layers=2)\n",
    "\n",
    "outputs, hidden = encoder(input_variable, lengths)\n",
    "print(outputs.shape, hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 7840]) torch.Size([1, 5, 20]) torch.Size([10, 5, 7840])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dungminhdang/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "attn_mode = 'dot'\n",
    "decoder = AttnDecoderGru(attn_mode, embedding, hidden_size, enc_layers=2, n_layers=1, output_size=voc.n_words)\n",
    "decoder_outputs, decoder_hidden = decoder(outputs, hidden, max_target_len, target_variable)\n",
    "print(decoder_outputs.shape, decoder_hidden.shape, decoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_outputs.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 7840]) torch.Size([1, 5, 20]) torch.Size([10, 5, 7840])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dungminhdang/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "attn_mode = 'general'\n",
    "decoder = AttnDecoderGru(attn_mode, embedding, hidden_size, enc_layers=2, n_layers=1, output_size=voc.n_words)\n",
    "decoder_outputs, decoder_hidden = decoder(outputs, hidden, max_target_len, target_variable)\n",
    "print(decoder_outputs.shape, decoder_hidden.shape, decoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_outputs.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 7840]) torch.Size([1, 5, 20]) torch.Size([10, 5, 7840])\n",
      "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "attn_mode = 'concat'\n",
    "decoder = AttnDecoderGru(attn_mode, embedding, hidden_size, enc_layers=2, n_layers=1, output_size=voc.n_words)\n",
    "decoder_outputs, decoder_hidden = decoder(outputs, hidden, max_target_len, target_variable)\n",
    "print(decoder_outputs.shape, decoder_hidden.shape, decoder_outputs.shape)\n",
    "print(decoder_outputs.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dungminhdang/anaconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100; Percent complete: 2.0%; Average loss: 4.5621\n",
      "Iteration: 200; Percent complete: 4.0%; Average loss: 2.9559\n",
      "Iteration: 300; Percent complete: 6.0%; Average loss: 2.8926\n",
      "Iteration: 400; Percent complete: 8.0%; Average loss: 2.7254\n",
      "Iteration: 500; Percent complete: 10.0%; Average loss: 2.6976\n",
      "Iteration: 600; Percent complete: 12.0%; Average loss: 2.7369\n",
      "Iteration: 700; Percent complete: 14.0%; Average loss: 2.6344\n",
      "Iteration: 800; Percent complete: 16.0%; Average loss: 2.6252\n",
      "Iteration: 900; Percent complete: 18.0%; Average loss: 2.5826\n",
      "Iteration: 1000; Percent complete: 20.0%; Average loss: 2.5540\n",
      "Iteration: 1100; Percent complete: 22.0%; Average loss: 2.5176\n",
      "Iteration: 1200; Percent complete: 24.0%; Average loss: 2.5154\n",
      "Iteration: 1300; Percent complete: 26.0%; Average loss: 2.4947\n",
      "Iteration: 1400; Percent complete: 28.0%; Average loss: 2.4704\n",
      "Iteration: 1500; Percent complete: 30.0%; Average loss: 2.4720\n",
      "Iteration: 1600; Percent complete: 32.0%; Average loss: 2.3845\n",
      "Iteration: 1700; Percent complete: 34.0%; Average loss: 2.4695\n",
      "Iteration: 1800; Percent complete: 36.0%; Average loss: 2.3921\n",
      "Iteration: 1900; Percent complete: 38.0%; Average loss: 2.4317\n",
      "Iteration: 2000; Percent complete: 40.0%; Average loss: 2.3689\n",
      "Iteration: 2100; Percent complete: 42.0%; Average loss: 2.3757\n",
      "Iteration: 2200; Percent complete: 44.0%; Average loss: 2.3290\n",
      "Iteration: 2300; Percent complete: 46.0%; Average loss: 2.3023\n",
      "Iteration: 2400; Percent complete: 48.0%; Average loss: 2.3304\n",
      "Iteration: 2500; Percent complete: 50.0%; Average loss: 2.2958\n",
      "Iteration: 2600; Percent complete: 52.0%; Average loss: 2.3362\n",
      "Iteration: 2700; Percent complete: 54.0%; Average loss: 2.3097\n",
      "Iteration: 2800; Percent complete: 56.0%; Average loss: 2.2687\n",
      "Iteration: 2900; Percent complete: 58.0%; Average loss: 2.2778\n",
      "Iteration: 3000; Percent complete: 60.0%; Average loss: 2.2736\n",
      "Iteration: 3100; Percent complete: 62.0%; Average loss: 2.2505\n",
      "Iteration: 3200; Percent complete: 64.0%; Average loss: 2.2302\n",
      "Iteration: 3300; Percent complete: 66.0%; Average loss: 2.2353\n",
      "Iteration: 3400; Percent complete: 68.0%; Average loss: 2.2596\n",
      "Iteration: 3500; Percent complete: 70.0%; Average loss: 2.2333\n",
      "Iteration: 3600; Percent complete: 72.0%; Average loss: 2.2285\n",
      "Iteration: 3700; Percent complete: 74.0%; Average loss: 2.2323\n",
      "Iteration: 3800; Percent complete: 76.0%; Average loss: 2.2433\n",
      "Iteration: 3900; Percent complete: 78.0%; Average loss: 2.2362\n",
      "Iteration: 4000; Percent complete: 80.0%; Average loss: 2.2137\n",
      "Iteration: 4100; Percent complete: 82.0%; Average loss: 2.1914\n",
      "Iteration: 4200; Percent complete: 84.0%; Average loss: 2.1841\n",
      "Iteration: 4300; Percent complete: 86.0%; Average loss: 2.2019\n",
      "Iteration: 4400; Percent complete: 88.0%; Average loss: 2.1766\n",
      "Iteration: 4500; Percent complete: 90.0%; Average loss: 2.1969\n",
      "Iteration: 4600; Percent complete: 92.0%; Average loss: 2.1748\n",
      "Iteration: 4700; Percent complete: 94.0%; Average loss: 2.1750\n",
      "Iteration: 4800; Percent complete: 96.0%; Average loss: 2.1584\n",
      "Iteration: 4900; Percent complete: 98.0%; Average loss: 2.1636\n",
      "Iteration: 5000; Percent complete: 100.0%; Average loss: 2.1547\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "encoder_n_layers = 1\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 32\n",
    "attn_mode = 'dot'\n",
    "\n",
    "embedding = nn.Embedding(voc.n_words, hidden_size)\n",
    "encoder = EncoderGru(embedding, hidden_size, encoder_n_layers, dropout)\n",
    "decoder = AttnDecoderGru(attn_mode, embedding, hidden_size, enc_layers=encoder_n_layers,\n",
    "                     n_layers=decoder_n_layers, output_size=voc.n_words, dropout_p=dropout)\n",
    "\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 5000\n",
    "print_every = 100\n",
    "\n",
    "embedding.train()\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "embedding_optimizer = torch.optim.Adam(embedding.parameters(), lr=learning_rate)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "\n",
    "print_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "for iteration in range(1, n_iteration + 1):\n",
    "    batch_data = batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "    \n",
    "    loss, n_mask = train_batch(batch_data, encoder, decoder, embedding,\n",
    "                encoder_optimizer, decoder_optimizer, embedding_optimizer,\n",
    "                clip, teacher_forcing_ratio)\n",
    "    \n",
    "    all_losses.append(loss)\n",
    "    print_loss += loss\n",
    "\n",
    "    if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3b6bc1760>]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'm', 'not', 'going', 'to', 'go', '.', '<EOS>', '<PAD>', '<PAD>']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalModel = EvaluateMode(encoder, decoder)\n",
    "evalModel.eval()\n",
    "\n",
    "\n",
    "evalModel.evaluate(voc, \"to do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> yea art thou there ?\n",
      "= put more into it !\n",
      ">> i m not a little . <EOS> <PAD> <PAD> <PAD>\n",
      "> she needed it .\n",
      "= a tip ! for the housekeeper !\n",
      ">> i m not going to go . <EOS> <PAD> <PAD>\n",
      "> how about that .\n",
      "= mmmm . you have children ?\n",
      ">> i m not going to be . <EOS> <PAD> <PAD>\n",
      "> yeah .\n",
      "= god ! unbelievable . vampires .\n",
      ">> you re not going to be here . <EOS> <PAD>\n",
      "> any minute now .\n",
      "= it s show time . don t look at\n",
      ">> i m not going to be . <EOS> <PAD> <PAD>\n",
      "> that s not why he s sending me .\n",
      "= why then .\n",
      ">> i m not going to go . <EOS> <PAD> <PAD>\n",
      "> a lot that means .\n",
      "= grace tell him .\n",
      ">> what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "> stop it .\n",
      "= i swear .\n",
      ">> what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "> well we ll have breakfast in the garden .\n",
      "= um hum . . .\n",
      ">> i m not going to go . <EOS> <PAD> <PAD>\n",
      "> we ll be there .\n",
      "= goodnight .\n",
      ">> i m not going to be . <EOS> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_batch = [random.choice(pairs) for _ in range(10)]\n",
    "\n",
    "for pair in eval_batch:\n",
    "    generated = ' '.join(evalModel.evaluate(voc, pair[0]))\n",
    "    print(f\"> {pair[0]}\")\n",
    "    print(f\"= {pair[1]}\")\n",
    "    print(f\">> {generated}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 200; Percent complete: 4.0%; Average loss: 3.4260\n",
      "Iteration: 400; Percent complete: 8.0%; Average loss: 2.7270\n",
      "Iteration: 600; Percent complete: 12.0%; Average loss: 2.6025\n",
      "Iteration: 800; Percent complete: 16.0%; Average loss: 2.5226\n",
      "Iteration: 1000; Percent complete: 20.0%; Average loss: 2.4298\n",
      "Iteration: 1200; Percent complete: 24.0%; Average loss: 2.3901\n",
      "Iteration: 1400; Percent complete: 28.0%; Average loss: 2.3267\n",
      "Iteration: 1600; Percent complete: 32.0%; Average loss: 2.2926\n",
      "Iteration: 1800; Percent complete: 36.0%; Average loss: 2.2949\n",
      "Iteration: 2000; Percent complete: 40.0%; Average loss: 2.2915\n",
      "Iteration: 2200; Percent complete: 44.0%; Average loss: 2.2425\n",
      "Iteration: 2400; Percent complete: 48.0%; Average loss: 2.2368\n",
      "Iteration: 2600; Percent complete: 52.0%; Average loss: 2.1852\n",
      "Iteration: 2800; Percent complete: 56.0%; Average loss: 2.1792\n",
      "Iteration: 3000; Percent complete: 60.0%; Average loss: 2.1514\n",
      "Iteration: 3200; Percent complete: 64.0%; Average loss: 2.1220\n",
      "Iteration: 3400; Percent complete: 68.0%; Average loss: 2.1241\n",
      "Iteration: 3600; Percent complete: 72.0%; Average loss: 2.0953\n",
      "Iteration: 3800; Percent complete: 76.0%; Average loss: 2.0793\n",
      "Iteration: 4000; Percent complete: 80.0%; Average loss: 2.0871\n",
      "Iteration: 4200; Percent complete: 84.0%; Average loss: 2.0540\n",
      "Iteration: 4400; Percent complete: 88.0%; Average loss: 2.0760\n",
      "Iteration: 4600; Percent complete: 92.0%; Average loss: 2.0344\n",
      "Iteration: 4800; Percent complete: 96.0%; Average loss: 2.0508\n",
      "Iteration: 5000; Percent complete: 100.0%; Average loss: 2.0103\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 3\n",
    "dropout = 0.1\n",
    "batch_size = 32\n",
    "attn_mode = 'general'\n",
    "\n",
    "embedding = nn.Embedding(voc.n_words, hidden_size)\n",
    "encoder = EncoderGru(embedding, hidden_size, encoder_n_layers, dropout)\n",
    "decoder = AttnDecoderGru(attn_mode, embedding, hidden_size, enc_layers=encoder_n_layers,\n",
    "                     n_layers=decoder_n_layers, output_size=voc.n_words, dropout_p=dropout)\n",
    "\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 5000\n",
    "print_every = 200\n",
    "\n",
    "embedding.train()\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "embedding_optimizer = torch.optim.Adam(embedding.parameters(), lr=learning_rate)\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "\n",
    "print_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "for iteration in range(1, n_iteration + 1):\n",
    "    batch_data = batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "    \n",
    "    loss, n_mask = train_batch(batch_data, encoder, decoder, embedding,\n",
    "                encoder_optimizer, decoder_optimizer, embedding_optimizer,\n",
    "                clip, teacher_forcing_ratio)\n",
    "    \n",
    "    all_losses.append(loss)\n",
    "    print_loss += loss\n",
    "\n",
    "    if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "> don t be ridiculous .\n",
      "= i have your word mister president ?\n",
      ">> i m sorry . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "====================\n",
      "> shes your dog jack .\n",
      "= no shes not .\n",
      ">> what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "====================\n",
      "> i don t know . . .\n",
      "= i want his name .\n",
      ">> i don t know . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "====================\n",
      "> yeah but where s the third guy ?\n",
      "= not in the bedroom . do it !\n",
      ">> i don t know . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "====================\n",
      "> bye .\n",
      "= bye .\n",
      ">> hi . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "====================\n",
      "> i m not myself since i stopped smoking .\n",
      "= oh when d you quit smoking ?\n",
      ">> what ? <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "====================\n",
      "> somebody hit you ?\n",
      "= it s not what you think .\n",
      ">> yeah . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "====================\n",
      "> what s in here then lead ?\n",
      "= it s my mother s piano .\n",
      ">> i don t know . <EOS> <PAD> <PAD> <PAD> <PAD>\n",
      "====================\n",
      "> yeah i crash there .\n",
      "= yeah good .\n",
      ">> you re not a good man . <EOS> <PAD> <PAD>\n",
      "====================\n",
      "> alright !\n",
      "= could take a little while though .\n",
      ">> i m sorry . <EOS> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "evalModel = EvaluateMode(encoder, decoder)\n",
    "evalModel.eval()\n",
    "\n",
    "eval_batch = [random.choice(pairs) for _ in range(10)]\n",
    "\n",
    "for pair in eval_batch:\n",
    "    generated = ' '.join(evalModel.evaluate(voc, pair[0]))\n",
    "    print(\"====================\")\n",
    "    print(f\"> {pair[0]}\")\n",
    "    print(f\"= {pair[1]}\")\n",
    "    print(f\">> {generated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3bfdbe670>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
